{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eUduHdRzRl3b"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kXHfhmj5Sg8I"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# set -m\n",
        "# git clone https://github.com/sachdevkartik/DeepLense.git\n",
        "# cd DeepLense && git checkout kartik_contribution\n",
        "# cd ..\n",
        "# mv DeepLense/Transformers_Classification_DeepLense_Kartik_Sachdev/* .\n",
        "# rm -rf DeepLense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GO-o2tDFTzRi"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c1HY0pEaLFG",
        "outputId": "faafc9b6-dc46-4152-9980-5117273aec44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Jul 30 19:21:27 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   88C    P8    10W /  N/A |      5MiB /  8192MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      2403      G   /usr/lib/xorg/Xorg                  4MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v5bBZlqLTw7f"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# pip3 install --upgrade -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p4PjBZQfY5oH"
      },
      "outputs": [],
      "source": [
        "# !pip uninstall numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dBA_SAO_Y6rq"
      },
      "outputs": [],
      "source": [
        "# !pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FLbLTB7NT-Iq"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import json\n",
        "import yaml\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "import torchvision\n",
        "from typing import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RtAGUsIfUCxM"
      },
      "outputs": [],
      "source": [
        "from utils.util import *\n",
        "from config.data_config import DATASET\n",
        "from utils.dataset import DefaultDatasetSetupSSL\n",
        "from self_supervised.losses.contrastive_loss import (\n",
        "    ContrastiveLossEuclidean,\n",
        "    ContrastiveLossEmbedding,\n",
        "    SimCLR_Loss,\n",
        "    NegativeCosineSimilarity,\n",
        ")\n",
        "from self_supervised.losses.sym_neg_cos_sim_loss import SymNegCosineSimilarityLoss\n",
        "\n",
        "from models.modules.head import BYOLProjectionHead, BYOLPredictionHead\n",
        "from utils.scheduler import cosine_schedule\n",
        "from torch.utils.data import DataLoader, random_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Rd3Ra8x_XG5D"
      },
      "outputs": [],
      "source": [
        "args = {\n",
        "    \"dataset_name\": \"Model_II\",\n",
        "    \"save\": \"data\",\n",
        "    \"num_workers\": 8,\n",
        "    \"train_config_path\": \"self_supervised/config/resnet_byol.yaml\",\n",
        "    \"cuda\": True,\n",
        "    \"log_dir\": \"logger\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "e_BlwV27XHye"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "dataset_name = args[\"dataset_name\"]\n",
        "dataset_dir = args[\"save\"]\n",
        "use_cuda = args[\"cuda\"]\n",
        "num_workers = args[\"num_workers\"]\n",
        "train_config_path = args[\"train_config_path\"]\n",
        "log_dir_base = args[\"log_dir\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "r3neGI8FXH6S"
      },
      "outputs": [],
      "source": [
        "classes = DATASET[f\"{dataset_name}\"][\"classes\"]\n",
        "num_classes = len(classes)\n",
        "\n",
        "# Open the YAML file and load its contents\n",
        "with open(train_config_path, \"r\") as file:\n",
        "    train_config = yaml.safe_load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Fk2BrahLXIQg"
      },
      "outputs": [],
      "source": [
        "epochs_pretrained = train_config[\"pretrained\"][\"num_epochs\"]\n",
        "epochs_finetuned = train_config[\"finetuned\"][\"num_epochs\"]\n",
        "\n",
        "learning_rate = train_config[\"optimizer_config\"][\"lr\"]\n",
        "margin = train_config[\"ssl\"][\"margin\"]\n",
        "num_channels = train_config[\"channels\"]\n",
        "temperature = train_config[\"ssl\"][\"temperature\"]\n",
        "network_type = train_config[\"network_type\"]\n",
        "image_size = train_config[\"image_size\"]\n",
        "optimizer_config = train_config[\"optimizer_config\"]\n",
        "\n",
        "backbone = train_config[\"backbone\"]\n",
        "\n",
        "make_directories([dataset_dir])\n",
        "seed_everything(seed=42)\n",
        "\n",
        "# logging\n",
        "current_time = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
        "log_dir = f\"{log_dir_base}/{current_time}\"\n",
        "init_logging_handler(log_dir_base, current_time)\n",
        "\n",
        "# dump config in logger\n",
        "with open(f\"{log_dir}/config.json\", \"w\") as fp:\n",
        "    json.dump(train_config, fp)\n",
        "\n",
        "# saving model path location\n",
        "model_path_pretrained = os.path.join(\n",
        "    f\"{log_dir}/checkpoint\",\n",
        "    f\"{network_type}_pretrained_{dataset_name}_{current_time}.pt\",\n",
        ")\n",
        "\n",
        "model_path_finetune = os.path.join(\n",
        "    f\"{log_dir}/checkpoint\",\n",
        "    f\"{network_type}_finetune_{dataset_name}_{current_time}.pt\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjU0UUKVXIiA",
        "outputId": "9abb6f3f-bc71-4bf3-8426-1e0fb0db15fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Multiple Transforms\n",
            ">>> Multiple Transforms\n"
          ]
        }
      ],
      "source": [
        "# setup default dataset\n",
        "default_dataset_setup = DefaultDatasetSetupSSL(dir=None)\n",
        "default_dataset_setup.setup(dataset_name=dataset_name)\n",
        "default_dataset_setup.setup_transforms(image_size=image_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zLBymamXIx5",
        "outputId": "55e7933c-730f-4f97-c206-3905378761b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model_II dataset already exists\n",
            "train data: 89104\n"
          ]
        }
      ],
      "source": [
        "# trainset\n",
        "train_dataset = default_dataset_setup.get_dataset(mode=\"train\")\n",
        "# default_dataset_setup.visualize_dataset(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxquTvHKUEN_",
        "outputId": "57116f52-9433-4ba5-dddb-e24585bacdeb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num of classes:  3\n",
            "torch.Size([64, 1, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "# split in train and valid set\n",
        "split_ratio = 0.25  # 0.25\n",
        "valid_len = int(split_ratio * len(train_dataset))\n",
        "train_len = len(train_dataset) - valid_len\n",
        "\n",
        "train_dataset, val_set = random_split(train_dataset, [train_len, valid_len])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_set, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
        ")\n",
        "\n",
        "# Load test dataset\n",
        "# testset = default_dataset_setup.get_dataset(mode=\"val\")\n",
        "# test_loader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# size check\n",
        "sample = next(iter(train_loader))\n",
        "print(\"num of classes: \", num_classes)\n",
        "print(sample[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BYOL2(nn.Module):\n",
        "    def __init__(self, backbone, num_ftrs=512):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = backbone\n",
        "        self.backbone[0] = nn.Conv2d(\n",
        "            1, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
        "        )\n",
        "\n",
        "        self.projection_head = BYOLProjectionHead(num_ftrs, 1024, 256)\n",
        "        self.prediction_head = BYOLPredictionHead(256, 1024, 256)\n",
        "\n",
        "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
        "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
        "\n",
        "        deactivate_requires_grad(self.backbone_momentum)\n",
        "        deactivate_requires_grad(self.projection_head_momentum)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(y)\n",
        "        p = self.prediction_head(z)\n",
        "        return p\n",
        "\n",
        "    def forward_momentum(self, x):\n",
        "        y = self.backbone_momentum(x).flatten(start_dim=1)\n",
        "        z = self.projection_head_momentum(y)\n",
        "        z = z.detach()\n",
        "        return z\n",
        "\n",
        "\n",
        "resnet = torchvision.models.resnet18()\n",
        "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "model = BYOL2(backbone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUdzIhd3YZyQ",
        "outputId": "60a4dd4d-1152-4f4a-ba9f-e332eacfc8b2"
      },
      "outputs": [],
      "source": [
        "# Create pretrain model\n",
        "resnet = torchvision.models.resnet34()\n",
        "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "\n",
        "num_ftrs_dict = {\n",
        "    \"resnet18\": 512,\n",
        "    \"resnet34\": 512,\n",
        "    \"resnet50\": 2048,\n",
        "\n",
        "}\n",
        "model = BYOL2(backbone, num_ftrs=num_ftrs_dict[\"resnet34\"])\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "# summary(model, input_size=(1, 1, 224, 224), device=\"cuda\")\n",
        "\n",
        "########################## Pretraining #############################\n",
        "\n",
        "# optimizer and loss function for pretrain\n",
        "optimizer_pretrain = torch.optim.SGD(model.parameters(), lr=0.06)\n",
        "\n",
        "# criterion\n",
        "criterion = NegativeCosineSimilarity()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/home/kartik/anaconda3/envs/dlvr/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2019: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [0/10], Batch [0/1045], Loss: -0.028086233884096146\n",
            "Epoch [0/10], Batch [10/1045], Loss: -0.5477247834205627\n",
            "Epoch [0/10], Batch [20/1045], Loss: -0.6095417737960815\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting Training\")\n",
        "for epoch in range(epochs_pretrained):\n",
        "    total_loss = 0\n",
        "    best_loss = float(\"inf\")\n",
        "\n",
        "    momentum_val = cosine_schedule(epoch, epochs_pretrained, 0.996, 1)\n",
        "    for batch_idx, (x0, x1, label) in enumerate(train_loader):\n",
        "        update_momentum(model.backbone, model.backbone_momentum, m=momentum_val)\n",
        "        update_momentum(\n",
        "            model.projection_head, model.projection_head_momentum, m=momentum_val\n",
        "        )\n",
        "        x0 = x0.to(device)\n",
        "        x1 = x1.to(device)\n",
        "        p0 = model(x0)\n",
        "        z0 = model.forward_momentum(x0)\n",
        "        p1 = model(x1)\n",
        "        z1 = model.forward_momentum(x1)\n",
        "        loss = 0.5 * (criterion(p0, z1) + criterion(p1, z0))\n",
        "        total_loss += loss.detach()\n",
        "        loss.backward()\n",
        "        optimizer_pretrain.step()\n",
        "        optimizer_pretrain.zero_grad()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch}/{epochs_pretrained}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item()}\"\n",
        "            )\n",
        "\n",
        "    if total_loss < best_loss:\n",
        "        best_loss = total_loss\n",
        "        best_model = copy.deepcopy(model)\n",
        "        torch.save(best_model.state_dict(), model_path_pretrained)\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYXa8R2bb_vD"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vVWofjN-Sp6f"
      },
      "source": [
        "# New Section"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
